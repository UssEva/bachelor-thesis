% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\newcommand{\numlarge}{152,007}
\newcommand{\monthstart}{December 2019}
\newcommand{\monthend}{January 2020}
\newcommand{\parsingexcp}{114}
\newcommand{\successfullyanalysed}{151,893}
\newcommand{\foundbugs}{100}
\newcommand{\modelduration}{72 h}
\newcommand{\bugfindingduration}{5 min}

\chapter{Evaluation}\label{chap:evaluation}
%TODO Unfinished chapter

The main research points for this bachelor's thesis are answers to the following questions:
\begin{itemize}
\item[\textbf{RQ1}] What is the optimal gram size for building an useful model?
\item[\textbf{RQ2}] How long should the analysed sequences be for an effective analysis process?
\item[\textbf{RQ3}] How effective are \ngram{s} for bug detection in comparison to \litterbox{}?
\item[\textbf{RQ4}] What kinds of violations were detected by the \ngram{}?
\end{itemize}
For the analysis a big dataset of \scratch{3} projects was used to create a descriptive model. Then a new set of projects was analysed to detect bugs and manually classify the problematic code blocks.


\section{Datasets}\label{sec:dataset}
%TODO Add introduction

\subsection{Model Training Set}\label{subsec:trainingset}
%TODO Add evaluation time, amount, gadgets,...
In order to have a sufficient number of scripts and sprites to calculate a probability distribution from, we decided to build the \ngram{} on a large dataset. The dataset consists of \numlarge\ \scratch\ projects. From \monthstart\ to \monthend\ we downloaded the most recent projects with the \scratch\ REST API\footnote{\url{https://github.com/LLK/scratch-rest-api/wiki}, last accessed May 8, 2020}. We did not exclude remixes from the dataset.

\subsection{Bug Finding Set}\label{subsec:bugset}
%TODO Add specification and criteria for bugset


\section{RQ1: Gram Size}\label{sec:gram_size}
%TODO Update execution
In order to find the best \textit{gram size} that should be used for the model building process, different n-gram models with \textit{gram sizes} ranging from 2 to 10 were built. After calculating the probabilities of each token sequence and ranking them based on their probabilities in descending order, the bottom 10 sequences of each list were manually examined. The \textit{gram size} that managed to find the most true bugs was chosen. (Add result...)

%TODO Add diagram: Bugs per gram size.


\section{RQ2: Sequence Length}\label{sec:sequence_length}
%TODO Update execution
The evaluation of the optimal sequence length for the analysis was executed by building n-gram models with the \textit{gram size} from RQ \ref{sec:gram_size} and {sequence lengths} in the range from 2 to 10. Calculating probabilities from all sequences and ranking them was followed by examining the bottom 10 sequences with low probabilities to check how many true bugs are detected. The \textit{sequence length} that helped to find the most bugs, is chosen as the optimal number. (Add results...)

%TODO Add diagram: Bugs per sequence length


\section{RQ3: Comparison to Litterbox}\label{sec:litterbox}
%TODO Find bugs with litterbox
On the same analysis set, \litterbox{} was used to find bugs and count how many of these bugs the \ngram{} can detect as well. (Add results...)

%TODO Update table: Project #LitterboxBugs #NgramBugs
\begin{table}[H]
    \centering
    \caption[The number of reported bugs found by \litterbox{} and N-gram model.]{\label{tab:aums-pupilset}The number of reported bugs found by \litterbox{} and N-gram model}
    \begin{tabular}{lrr}
        \toprule
        Project & \#LitterboxBugs & \#NgramBugs \\
        \midrule
        Fruit Catching & 42 & 295 \\
        \bottomrule
    \end{tabular}
\end{table}
 
 
\section{RQ4: Violation Classification}\label{sec:violations}
%TODO Find bugs and show examples
Procedure  continued by analysing if \ngram{} found bugs that are not detected by \litterbox{}. After all potential bugs were collected in the candidate bug set, the defective code was manually classified into these categories: \textit{True Bugs, Refactoring Opportunities or False Positives}. (Add results...)

%TODO Update table: #ReportedBugs #TrueBugs #Refactoring #FalsePositive
\begin{table}[H]
    \centering
    \caption[The categorization of all reported bugs.]{\label{tab:aums-pupilset}The categorization of all reported bugs}
    \begin{tabular}{lrrr}
        \toprule
        \#ReportedBugs & \#TrueBugs & \#Refactoring & \#FalsePositive \\
        \midrule
        150 & 42 & 95 & 13 \\
        \bottomrule
    \end{tabular}
\end{table}


\section{Threats to Validity}\label{sec:threats-to-validity}
%TODO Add threats to validity
Threats to validity ...

