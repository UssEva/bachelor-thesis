% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\newcommand{\numlarge}{152,007}
\newcommand{\monthstart}{December 2019}
\newcommand{\monthend}{January 2020}
\newcommand{\parsingexcp}{?}
\newcommand{\successfullyanalysed}{?}
\newcommand{\creationtime}{?}

\chapter{Evaluation}\label{chap:evaluation}
%TODO Unfinished chapter

The main research points for this bachelor's thesis are answers to the following questions:
\begin{itemize}
\item[\textbf{RQ1}] What is the optimal gram size for building a useful model?
\item[\textbf{RQ2}] How long should the analysed sequences be for an effective analysis process?
\item[\textbf{RQ3}] How effective are \ngram{s} for bug detection in comparison to \litterbox{}?
\item[\textbf{RQ4}] What kinds of violations were detected by the \ngram{}?
\item[\textbf{RQ5}] Efficiency of general \ngram{} vs project-specific model?
\end{itemize}


\section{Datasets}\label{sec:dataset}
This section shows the two different datasets that were used for the bachelor's thesis, specifically, for the training of the model like it is introduced in Subsection~\ref{subsec:trainingset} and for bug detection which Subsection~\ref{subsec:bugset} focuses on.

\subsection{Model Training Set}\label{subsec:trainingset}
%TODO Add evaluation time, amount, gadgets,...
In order to have a sufficient number of sequences to calculate a probability distribution from, we decided to build the \ngram{} on a large dataset. The dataset consists of \numlarge\ \scratch\ projects. From \monthstart\ to \monthend\ we downloaded the most recent projects with the \scratch\ REST API\footnote{\url{https://github.com/LLK/scratch-rest-api/wiki}, last accessed May 8, 2020}. We did not exclude remixes from the dataset. \litterbox\ could not parse \parsingexcp\ projects, thus the \ngram\ was created of \successfullyanalysed\ projects without any exceptions. The creation of the model took \creationtime\ and was conducted on machines equipped with Intel Xeon E5-2650 v2 @ 2.60 GHz CPUs with 256 GiB of RAM.

\subsection{Bug Finding Set}\label{subsec:bugset}
The second dataset we use to evaluate the \ngram{} is a set of correct as well as defective solutions for five small coding tasks for students. Based on the task the pupils had to implement, we call these sets \textit{Monkey}, \textit{Elephant}, \textit{Cat}, \textit{Horse} and \textit{Fruit Catching} task.
We used solutions of pupils which originate in primary programming education~\cite{katharina} for the Monkey, Elephant, Cat and Horse tasks. For the Fruit Catching task we used the same dataset as Stahlbauer et al. in their work about testing \scratch\ programs automatically~\cite{whisker}. Table~\ref{tab:big-dataset} shows the number of projects for each task. The bug detection was done in a few seconds for every set of solutions and did not throw any exceptions. All experiments with the small datasets were conducted on a Swift SF314-57 with an Intel i5 core and 8 GB RAM.

 
\begin{table}[H]
    \centering
    \caption[Projects evaluated in our experiments]{\label{tab:big-dataset}Projects evaluated in our experiments}
    \begin{tabular}{lr}
        \toprule
        Task & \#Projects \\
        \midrule
        Fruit Catching & 42 \\
        Monkey & 120 \\
        Elephant & 130 \\
        Cat & 129 \\
        Horse & 73 \\
        \bottomrule
    \end{tabular}
\end{table}


\section{RQ1: Gram Size}\label{sec:gram_size}
%TODO Update execution and add result
In order to find the best \textit{gram size} that increases the number of detected bugs, different n-gram models with \textit{gram sizes} ranging from 2 to 6 were built based on the large dataset from Section~\ref{sec:dataset}. After calculating the probabilities of each token sequence and ranking them based on their probabilities in descending order, the bottom 10 sequences of each list were manually examined. The \textit{gram size} that managed to find the most true bugs was chosen which in this case was the \textit{gram size} ? like it is shown in Figure~\ref{fig:bugs-gramSize}. 

%TODO Add diagram: Bugs per gram size.


\section{RQ2: Sequence Length}\label{sec:sequence_length}
%TODO Update execution, add result
The evaluation of the optimal sequence length for the analysis was executed by building n-gram models based on the dataset from Section~\ref{sec:dataset} with the optimal \textit{gram size} from Section~\ref{sec:gram_size} and {sequence lengths} in the range from 2 to 10. Calculating probabilities from all sequences and ranking them was followed by examining the bottom 10 sequences with low probabilities to check how many true bugs are detected. The \textit{sequence length} that helped to find the most bugs is chosen as the optimal number which is ? according to ~\ref{tab:bugs-sequenceLength}. 

%TODO Add diagram: Bugs per sequence length


\section{RQ3: Comparison to Litterbox}\label{sec:litterbox}
%TODO Find bugs with litterbox, fix gram size and sequence lengh, add results
After setting the \textit{gram size} and \textit{sequence length} both on a fixed size based on the information that was gathered by the first two research questions, the same set of projects is used for a comparison between \litterbox{} and \ngram{} approach. The same projects from Section~\ref{sec:dataset} are analysed by \litterbox{} and the \ngram{} to test how many sequences are reported with the different methods. Table~\ref{tab:litterbox} shows the amount of reported bugs of each method. 

%TODO Update table: Project #LitterboxBugs #NgramBugs
\begin{table}[H]
    \centering
    \caption[The number of reported bugs found by \litterbox{} and N-gram model]{\label{tab:litterbox}The number of reported bugs found by \litterbox{} and N-gram model}
    \begin{tabular}{lrr}
        \toprule
        Task & \#LitterboxBugs & \#NgramBugs \\
        \midrule
        Fruit Catching &  &\\
        Monkey &  &  \\
        Elephant &  & \\
        Cat &  &  \\
        Horse & &  \\
        \bottomrule
    \end{tabular}
\end{table}
 
 
\section{RQ4: Violation Classification}\label{sec:violations}
%TODO Find bugs and show examples, add results
The analysis procedure is continued by analysing specifically the bugs that are reported by the \ngram{}. For each task the project with the most found bugs is manually analysed to estimate the rate of false positives. Table~\ref{tab:small-dataset} shows the projects that were chosen for further assessment as well as their further information.

\begin{table}[H]
    \centering
    \caption[Small Dataset with one project of each task]{\label{tab:small-dataset}Small dataset}
    \begin{tabular}{lrrrr}
        \toprule
        Task & Project & Size & \#Scripts & \#Blocks \\
        \midrule
        Fruit Catching  & & & & \\
        Monkey  & & & &  \\
        Elephant  & & & & \\
        Cat  & & & &  \\
        Horse & & & & \\
        \bottomrule
    \end{tabular}
\end{table}

After all by \ngram{} detected potential bugs were collected in the candidate bug set, the defective code is manually classified into the following categories: \textit{True Bugs, Refactoring Opportunities or False Positives}. Table~\ref{tab:violations} displays the numbers for each category.

%TODO Update table: #ReportedBugs #TrueBugs #Refactoring #FalsePositive
\begin{table}[H]
    \centering
    \caption[The categorization of all reported bugs]{\label{tab:violations}The categorization of all reported bugs}
    \begin{tabular}{lrrrr}
        \toprule
        Task & \#ReportedBugs & \#TrueBugs & \#Refactoring & \#FalsePositive \\
        \midrule
        Fruit Catching  & & & & \\
        Monkey  & & & &  \\
        Elephant  & & & & \\
        Cat  & & & &  \\
        Horse & & & & \\
        \bottomrule
    \end{tabular}
\end{table}


\section{RQ5: Project-specific Model}\label{sec:project-specific}
%TODO Add comparison between general and project-specific model, Add results
Instead of one model that is based on a large dataset, we also used many smaller models that are specific to the project we want to analyse. For each pupil's task, we created a model out of the given solutions and its reference solution. This way the model has specific data that is related to the task.

%TODO Update table: #GeneralModelBugs #SpecificModelBugs 
\begin{table}[H]
    \centering
    \caption[Found bugs by general model vs project-specific model]{\label{tab:violations}Found bugs by general model vs project-specific model}
    \begin{tabular}{lrr}
        \toprule
        Task & \#GeneralModelBugs & \#SpecificModelBugs \\
        \midrule
        Fruit Catching  & &  \\
        Monkey  & & \\
        Elephant  & &  \\
        Cat  & &  \\
        Horse & & \\
        \bottomrule
    \end{tabular}
\end{table}
