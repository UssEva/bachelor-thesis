% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex
\chapter{Background}\label{chap:background}
As this thesis merges known concepts from \scratch{} analysis and \ngram{}, we introduce the concepts our work is based on in the following sections. Section~\ref{sec:analysing-scratch} introduces \scratch{} and the already existing methods of bug detection in \scratch. Section~\ref{sec:language-models} introduces the concept of a \ngram{}. It is necessary to understand the difference between n-grams and a n-gram model and the way of using it in order to obtain valuable information about the given code.


\section{Analysing Scratch Programs}\label{sec:analysing-scratch}
The tools \drscratch{}~\cite{drscratch} as well as \hairball{}~\cite{hairball} analyse \scratch{} programs to find bugs and code smells. These are then reported to the user in order to improve the computational thinking and coding skills of novice programmers. Bad programming habits were assessed in a preliminary study by Moreno et al.~\cite{badhabits} and code smells that are very common in Scratch were analysed by Vargas-Alba et al.~\cite{badsmells}. Stahlbauer et al.~\cite{whisker} introduced \whisker{} which is a formal testing framework for Scratch. \litterbox, a tool created by Fr√§drich et al.~\cite{scratch_bugpatterns} that creates an AST of \scratch{} programs, is used for finding code smells as well as bug patterns. In this bachelor thesis, the goal is to enhance \litterbox{} by finding bugs with a \ngram{} instead of bug patterns and rules like all tools mentioned above are already able to do.


\section{N-gram Language Models}\label{sec:language-models}
Hindle et al.~\cite{naturalness} first introduced the \ngram{} to show that software source code is highly repetitive and the \ngram{} can be used in code suggestion and completion. This work is the basis for using language models to model source code and demonstrated how they could be used in software tools. A very accurate algorithm by using a Hidden Markov Model for code completion was proposed by Han et al.~\cite{codecompletion}. SLAMC by Nguyen et al.~\cite{SLAMC}, which incorporated semantic information into a n-gram model, presented a method to code suggestion. It demonstrated how tokens can be seen more semantically instead of just syntactically. Raychev et al.~\cite{SLANG} investigated the effectiveness of various language models for code completion, i.e., n-gram and recurrent neural networks. By combining program analysis and the n-gram model, they proposed SLANG, which had the goal to predict the sequence of method calls in a software system. This work leverages the \ngram{} on a new domain - software defect detection in \scratch{}.

