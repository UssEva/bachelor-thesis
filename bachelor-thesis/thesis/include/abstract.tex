% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex
\chapter*{Abstract}
%TODO Unfinished chapter!

In contrast to rule-based methods which often rely on special patterns that appear rather frequently in source code, and detect violations based on the inferred rules, \ngram{} is another approach to bug detection. In this bachelor thesis, this new way of software bug detection is proposed in order to improve software reliability and improve the quality of \scratch{} programs.

After the tokenization, token sequences are assessed with their calculated probabilities which are based on the existing model. If a detected token sequence has a rather low probability, it gets reported as a potential bug because the assumption is that these kinds of sequential tokens are unusual and should be highlighted to the programmer as a bad practice or programming mistake that affects the program.

The \ngram{} gets evaluated in the following ways. First, the parameters for the creation of the n-gram model, especially \textit{Gram Size} and \textit{Sequence Length} have to be analysed to find the optimal configuration of the model. (Add results...) Second, \scratch{} projects are analysed to find bugs, code smells or refactoring opportunities. Then the result is compared to the reported bugs by \litterbox{} which assesses the same projects. (Add results...) As a last step, the detected bugs are categorized to identify if \ngram{s} are suitable for the bug detection in \scratch{} projects and if this implementation is able to compete with already existing approaches like \litterbox{}. (Add results...) The results suggest that the implementation this bachelor thesis is referring to is complementary(?) to the above mentioned methods of software analyzation.
%TODO Add evaluation results
 