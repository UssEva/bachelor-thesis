% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex
\chapter*{Abstract}
%TODO Unfinished chapter!

In contrast to rule-based methods which often rely on special patterns that appear rather frequently in source code, and detect violations based on the inferred rules, \ngram{} is another approach to bug detection. In this bachelor's thesis, this new way of software bug detection is proposed in order to improve software reliability and improve the quality of \scratch{} programs.

After the tokenization, token sequences are assessed with their calculated probabilities which are based on the existing model. If a detected token sequence has a rather low probability, it gets reported as a potential bug because the assumption is that these kinds of sequential tokens are unusual and should be highlighted to the programmer as a bad practice or programming mistake that affects the program.

%TODO Add evaluation results
The \ngram{} gets evaluated in the following ways. First, the parameters for the creation of the n-gram model, especially \textit{gram size} and \textit{sequence length} have to be analysed to find the optimal configuration of the model. (Add results...) Second, \scratch{} projects are analysed to find bugs, code smells or unusual use cases. Then the result is compared to the reported bugs by \litterbox{} which assesses the same projects. (Add results...) Third, the detected bugs are categorized to identify if \ngram{s} are suitable for bug detection in \scratch{} projects and if this implementation is able to compete with already existing approaches like \litterbox{}. (Add results...) At last, it is evaluated if project-specific models are more efficient in detecting defective \scratch\ code than a model that is based on a random dataset. (Add results...) The results suggest that the implementation this bachelor's thesis is referring to is complementary(?) to the above mentioned methods of software analysation.